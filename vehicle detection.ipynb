{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7465839e-ed37-4d7d-a747-c94079a9391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from vidgear.gears import VideoGear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d4f362-1011-4663-a0ad-3729852f19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO = \"video/object_detection_road.mp4\"\n",
    "BORDER_INCREASE = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4c972d-37e0-4c19-93a2-40e541469632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stabilise video feed\n",
    "vidcap = VideoGear(source=VIDEO, stabilize = True).start()\n",
    "\n",
    "frame1 = vidcap.read()\n",
    "frame2 = vidcap.read()\n",
    "\n",
    "while frame2 is not None:\n",
    "    #Find difference between two frames\n",
    "    frame1 = np.ascontiguousarray(frame1, dtype=np.uint8)\n",
    "    frame2 = np.ascontiguousarray(frame2, dtype=np.uint8)\n",
    "    \n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Irrelevant parts of frame blocked out\n",
    "    #Top of frame, stabilisation makes it shakey and unreliable for detection\n",
    "    cv2.rectangle(gray, (0, 0), (1920, 50), (0,0,0), -1)\n",
    "    \n",
    "    #Trees on left side\n",
    "    vertices = np.array([[0, 1080], [0, 0], [1075, 0], [300,1080]], np.int32)\n",
    "    pts = vertices.reshape((-1, 1, 2))\n",
    "    cv2.polylines(gray, [pts], isClosed=True, color=(0, 0, 0), thickness=20)\n",
    "    cv2.fillPoly(gray, [pts], color=(0, 0, 0))\n",
    "    \n",
    "    #Trees on right side\n",
    "    vertices = np.array([[1920, 1080], [1920, 0], [1250, 0]], np.int32)\n",
    "    pts = vertices.reshape((-1, 1, 2))\n",
    "    cv2.polylines(gray, [pts], isClosed=True, color=(0, 0, 0), thickness=20)\n",
    "    cv2.fillPoly(gray, [pts], color=(0, 0, 0))\n",
    "    \n",
    "    #Outline areas of movement\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 40, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations = 3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #Multiple contours are produced which may overlapped each other or belong to the same vehicle\n",
    "    #Create a heatmap of these areas to produce a single contour for each area of movement\n",
    "    AoI = np.ascontiguousarray(np.zeros(shape=frame1.shape), dtype=np.uint8)\n",
    "\n",
    "    for con in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(con)\n",
    "        \n",
    "        #Ignore contour if it is too small\n",
    "        if cv2.contourArea(con) < 500:\n",
    "            continue\n",
    "        \n",
    "        #Increase the size of each contour incase it is too small\n",
    "        h_diff = int(w*BORDER_INCREASE)\n",
    "        w_diff = int(h*BORDER_INCREASE)\n",
    "\n",
    "        cv2.rectangle(AoI, (x-h_diff, y-w_diff), (x+w+h_diff, y+h+w_diff), (255,255,255), -1)\n",
    "    \n",
    "    #create new contours for these areas and display them on first frame\n",
    "    AoI = cv2.cvtColor(AoI, cv2.COLOR_BGR2GRAY)\n",
    "    contours, _ = cv2.findContours(AoI, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for con in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(con)\n",
    "        \n",
    "        if cv2.contourArea(con) < 500:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0,0,0), 2)\n",
    "    \n",
    "    #Show frame\n",
    "    cv2.imshow('Frame',frame1)\n",
    "    frame1 = frame2\n",
    "    \n",
    "    #Skip next two frames to allow for better detection of movement\n",
    "    for x in range(2):\n",
    "        frame2 = vidcap.read()\n",
    "    \n",
    "    if frame2 is not None:\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf615e-dfed-4bee-a951-fcff44120ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
